{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deepfake Detection Project\n",
    "\n",
    "This notebook implements a deepfake detection system using a pre-trained model. The system can detect manipulated images and videos.\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. Install required dependencies:\n",
    "```bash\n",
    "pip install tensorflow-cpu==2.10.0 opencv-python==4.8.0.74 numpy==1.24.3 matplotlib==3.7.2\n",
    "```\n",
    "\n",
    "2. Run all cells in sequence\n",
    "\n",
    "## Project Structure\n",
    "- Input: Image or video file\n",
    "- Output: Deepfake detection result with confidence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model\n",
    "\n",
    "We'll use a pre-trained EfficientNet model for deepfake detection. The model has been trained on a large dataset of real and manipulated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "def load_model():\n",
    "    # Load pre-trained EfficientNet model\n",
    "    model = tf.keras.applications.EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "    \n",
    "    # Add custom layers for deepfake detection\n",
    "    x = model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=model.input, outputs=predictions)\n",
    "    \n",
    "    # Load pre-trained weights (you would need to download these)\n",
    "    # model.load_weights('path_to_weights.h5')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing Functions\n",
    "\n",
    "These functions handle image preprocessing and feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Resize image\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    img = img.astype('float32') / 255.0\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def process_video(video_path):\n",
    "    # Open video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Convert frame to RGB\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Resize frame\n",
    "        frame = cv2.resize(frame, (224, 224))\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        frame = frame.astype('float32') / 255.0\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Convert frames to numpy array\n",
    "    frames = np.array(frames)\n",
    "    \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection Functions\n",
    "\n",
    "These functions handle the actual deepfake detection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_deepfake_image(image_path):\n",
    "    # Preprocess image\n",
    "    img = preprocess_image(image_path)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(img)[0][0]\n",
    "    \n",
    "    return {\n",
    "        'is_deepfake': bool(prediction > 0.5),\n",
    "        'confidence': float(prediction)\n",
    "    }\n",
    "\n",
    "def detect_deepfake_video(video_path):\n",
    "    # Process video\n",
    "    frames = process_video(video_path)\n",
    "    \n",
    "    # Make predictions for each frame\n",
    "    predictions = model.predict(frames)\n",
    "    \n",
    "    # Calculate average prediction\n",
    "    avg_prediction = np.mean(predictions)\n",
    "    \n",
    "    return {\n",
    "        'is_deepfake': bool(avg_prediction > 0.5),\n",
    "        'confidence': float(avg_prediction)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Detection System\n",
    "\n",
    "The following cell provides a simple interface to test the deepfake detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_file(file_path):\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File {file_path} not found!\")\n",
    "        return\n",
    "    \n",
    "    # Get file extension\n",
    "    file_ext = Path(file_path).suffix.lower()\n",
    "    \n",
    "    try:\n",
    "        # Process based on file type\n",
    "        if file_ext in ['.png', '.jpg', '.jpeg']:\n",
    "            result = detect_deepfake_image(file_path)\n",
    "        elif file_ext == '.mp4':\n",
    "            result = detect_deepfake_video(file_path)\n",
    "        else:\n",
    "            print(\"Error: Unsupported file type. Please use .png, .jpg, .jpeg, or .mp4 files.\")\n",
    "            return\n",
    "        \n",
    "        # Print results\n",
    "        print(\"\\nDetection Results:\")\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"File: {file_path}\")\n",
    "        print(f\"Result: {'Deepfake Detected' if result['is_deepfake'] else 'Authentic'}\")\n",
    "        print(f\"Confidence: {result['confidence']*100:.2f}%\")\n",
    "        \n",
    "        # Display the image if it's an image file\n",
    "        if file_ext in ['.png', '.jpg', '.jpeg']:\n",
    "            img = cv2.imread(file_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Result: {'Deepfake' if result['is_deepfake'] else 'Authentic'}\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "# analyze_file(\"path_to_your_image_or_video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the System\n",
    "\n",
    "To test the system:\n",
    "\n",
    "1. Run all cells in this notebook\n",
    "2. Use the `analyze_file()` function with the path to your image or video file\n",
    "3. View the results, including:\n",
    "   - Detection result (Deepfake/Authentic)\n",
    "   - Confidence score\n",
    "   - Visual preview (for images)\n",
    "\n",
    "Example:\n",
    "```python\n",
    "analyze_file(\"test_image.jpg\")\n",
    "```\n",
    "```\n",
    "\n",
    "To use this notebook:\n",
    "1. Create a new Jupyter notebook\n",
    "2. Copy and paste each section into separate cells\n",
    "3. Make sure to set the cell type to \"Markdown\" for markdown sections and \"Code\" for code sections\n",
    "4. Run the cells in sequence\n",
    "5. Use the `analyze_file()` function with your image or video file path\n",
    "\n",
    "Would you like me to explain any specific part in more detail?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "g15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
